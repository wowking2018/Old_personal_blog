---
layout:     post
title:      卷积
subtitle:   对卷积形象化的理解以及摘要
date:       2022-07-10
author:     wowking
header-img: img/blog4/bk.png
catalog: true
tags:
    - 数学
    - 图像处理
    - 机器学习
---

## 对卷积的理解

### 1. 卷积的通俗理解

#### 1.1 从Dirac函数出发

通俗来讲：**你在过去不同时刻惹女朋友生气的叠加，对女朋友现在坏心情的贡献就是卷积.**

为什么呢？设当前时刻为 $t$，惹女朋友生气用输入函数 $\delta(t)$ 描述，女朋友心情用输出函数 $h(t)$描述，假设女朋友现在不开心的结果是以前所有不开心的叠加（实际情况往往如此，这就是因果关系).

**注:** Dirac函数 $\delta(t)$ 为点源.则在 $t_ {1}$ 时刻，惹女朋友生气为 $\delta\left(t-t_ {1}\right)$ ，此时女朋友的心情为 $h\left(t-t_ {1}\right)$ .为什么是 $t-t_ {1}$ ，可这样理解，当时很生气（ $t_ {1}$ 时刻 $)$ ，随着时间的流逝，可能就不怎么生气了.用数学符号表示为:

$$
\begin{equation}
    C\left(t-t_ {1}\right)=\int_ {t_ {1}}^{t} \delta\left(\tau-t_ {1}\right) h(t-\tau) \mathrm{d} \tau=h\left(t-t_ {1}\right)
\end{equation}
$$

$C(t)$ 代表当前时刻的坏心情，由于是对当前的影响，因此积分上限为. 同理，男朋友肯定会在不同时刻 $t_ {i}$ 若女朋友生气，表示为 $\delta\left(t-t_ {i}\right)$，与之对应的响应为 $h\left(t-t_ {i}\right)$ ，女朋友当前时刻的坏心情应是这些响应的叠加，则:

$$
\begin{equation}
    \begin{aligned}
        C(t)&=\sum_ {i} C\left(t-t_ {i}\right)=\sum_ {i} \int_ {t_ {i}}^{t} \delta\left(\tau-t_ {i}\right) h(t-\tau) \mathrm{d} \tau \\
        &=\int_ {t_ {i}}^{t}\left(\sum_ {i} \delta\left(\tau-t_ {i}\right)\right) h(t-\tau) \mathrm{d} \tau .
    \end{aligned}
\end{equation}
$$

令 $\sum_ {i} \delta\left(\tau-t_ {i}\right)=s(\tau)$，则卷积定义为：

$$
\begin{equation}
    C(t)=s(t) * h(t)=\int_ {-\infty}^{\infty} s(\tau) h(t-\tau) \mathrm{d} \tau=\sum_ {i} h\left(t-t_ {i}\right)
\end{equation}
$$

#### 1.2 从两个函数之间关系角度去看

其实，卷积的本质就是翻转，相乘，相加的这么一个过程. 我们不妨想象一下一辆火车进入隧道这一过程，[^1]

<img src="https://wowking2018.github.io/img/blog4/fig1.jpg" style="zoom: 100%;" width="500px"/>

假设一辆火车 $g(t)$ 和一个山洞 $f(t)$ 在同一个数轴上，初始情况下火车车头和山洞入口的朝向相同，我们需要描述火车进入山洞这一过程. 用数学语言来描述，把车口翻转就是把 $g(\tau)$ 变成 $g(-\tau)$， 在全局变量的影响下用 $g(t-\tau)$ 描述火车运动起来，$f(\tau) g(t-\tau)$表示火车进入山洞后每一时刻 $t$ 两者相对的位置. 积分就是累加和，则记录了进洞后两者不断重叠互相作用的过程.  



### 2.卷积的数学定义

设两函数为 $f(\vec{x}) ， g(\vec{x}) ， \vec{x}$ 为 $n$ 维向量，则 $f(\vec{x})$ 与 $g(\vec{x})$ 卷积定义为: 

$$
\begin{equation}
    C(\vec{x})=f(\vec{x}) * g(\vec{x})=\int_ {-\infty}^{+\infty} f(\vec{y}) g(\vec{x}-\vec{y}) \mathrm{d}^{n} \vec{y}
\end{equation}
$$

特别地，在一维情况下:

$$
\begin{equation}
    f(x) * g(x)=\int_ {-\infty}^{+\infty} f(y) g(x-y) d y
\end{equation}
$$

在离散形式下，又有如下形式：

$$
\begin{equation}
    \begin{gathered}
    (f * g)[n] \stackrel{\text { def }}{=} \sum_{m=-\infty}^{\infty} f[m] g[n-m] \\
    =\sum_{m=-\infty}^{\infty} f[n-m] g[m]
    \end{gathered}
\end{equation}
$$


### 3.卷积的基本性质

除一般性质（例如交换律，结合律，分配律等）以外，需要特别说明的性质如下：

$$
\begin{equation}
    \begin{aligned}
    \frac{\partial^{p}}{\partial x_ {i} \partial x_ {j} \partial x_ {k} \ldots}(f * g)&=f * \frac{\partial^{p} g}{\partial x_ {i} \partial x_ {j} \partial x_ {k} \ldots} \\
    &=\frac{\partial f}{\partial x_ {i}} * \frac{\partial^{p-1} g}{\partial x_ {j} \partial x_ {k} \ldots} \\
    &=\ldots \\
    &=\frac{\partial^{p} f}{\partial x_ {i} \partial x_ {j} \partial x_ {k} \ldots} * g .
    \end{aligned}
\end{equation}
$$

时域卷积定理: $\mathcal{F}(s * h)=\mathcal{F}(s) \mathcal{F}(h)$. 

$$
\begin{equation}
    \mathcal{F}(s * h)=\int_{-\infty}^{+\infty}\{\int_{-\infty}^{+\infty} s(y) h(x-y) \mathrm{d} y\} e^{-i k x} \mathrm{~d} x
\end{equation}
$$

令$x-y=t \Rightarrow x=y+t, \mathrm{d} x=\mathrm{d} t$ 

$$
\begin{equation}
    \begin{aligned}
    &R H S=\int_ {-\infty}^{+\infty}  \{\int_ {-\infty}^{+\infty} s(y) h(t) d y  \} e^{-i k(y+t)} \mathrm{d} t \\
    &=\int_ {-\infty}^{+\infty} s(y) e^{-i k y} d y \int_ {-\infty}^{+\infty} h(t) e^{-i k t} \mathrm{d} t \\
    &=\mathcal{F}(s) \mathcal{F}(h)
    \end{aligned}
\end{equation}
$$

频域卷积定理: $\frac{1}{2 \pi} \mathcal{F}(s) * \mathcal{F}(h)=\mathcal{F}(s \cdot h)$. 时间域卷积，频率域乘积；频率域卷积，时间域乘积. 这两个性质揭示了时域和频域有某种对称性，时域的乘法与频域卷积或时域卷积与频域乘法是具有对称性的，有了这个工具，我们在处理问题的时候就可以随意转换，哪个域方便就在哪个域计算.



### 4. 卷积与相关（correlation）

卷积描述的是两个信号间的相互作用，相关描述的是两个信号之间的相似性，这包括自相关与互相 关.用数学语言，相关定义为[^2]：

$$
\begin{equation}
    R(t)=s(t) \star h(t)=\int_{-\infty}^{\infty} s(\tau-t) h(\tau) d \tau=\int_{-\infty}^{\infty} s(\tau) h(\tau+t) d \tau.
\end{equation}
$$

其特点为: 两个函数没有反转，都是正的 $\tau$ ；而卷积的话需要反转系统响应函数(将 $\tau$ 变为 $-\tau$ ).注意相关不具有交换性，即 $s(t) \star h(t) \neq h(t) \star s(t)$. 现在我们将两者放在一起对比——

$$
\begin{equation}
    f(x) * g(x)=\int_ {-\infty}^{+\infty} f(y) g(x-y) \mathrm{d} y \qquad s(t) \star h(t)=\int_{-\infty}^{\infty} s(\tau-t) h(\tau) \mathrm{d} \tau
\end{equation}
$$

两者其实非常相似，但是仔细观察下发现两者并不相同，并可以通过如下形式进行转化：

$$
\begin{equation}
    \begin{aligned}
    &a(t) * b(t)=\int_{-\infty}^{\infty} a(\tau) b(t-\tau) d \tau=\int_{-\infty}^{\infty} a(t-\tau) b(\tau) d \tau \\
    &=\int_{-\infty}^{\infty} a(-(\tau-t)) b(\tau) d \tau=a(-t) \star b(t)
    \end{aligned}
\end{equation}
$$

### 5. 卷积在图像处理中的运用

卷积在图像处理中有重要的运用，同时在很多时候会与傅里叶变换相结合，在这里举一个很普遍的例子.可以把图像认为是函数 $f$，卷积核是函数 $g$，因为图像中卷积核是稳定的，就是那9个数，而卷积核每次在图像上滑动过程中，图像对应的窗口时变动的，是不稳定的.

以下图为例，拿一个3x3大小的窗口在图像上从左到右，从上到下滑动，每次都是逐点相乘，最终相加的过程[^3].

<img src="https://wowking2018.github.io/img/blog4/fig2.gif" style="zoom: 36%;" width="800px"/>





### 参考资料

[^1]: [卷积直观形象的实例](https://www.bilibili.com/video/BV1Di4y1o7vX)

[^2]: [卷积, 相关与反卷积](https://zhuanlan.zhihu.com/p/196786958)

[^3]: [Convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network)
