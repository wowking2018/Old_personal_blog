---
layout:     post
title:      数值积分
subtitle:   数值积分的基本方法(笔记)
date:       2022-07-31
author:     wowking
header-img: img/blog7/bk.jpg
catalog: true
tags:
    - 数学
    - 数值积分
---
## 数值积分方法

### 1. 数值积分思想基础

数值积分作为一种数值计算方法，用于求解复杂函数的积分，被广泛应用于科学计算、工程设计等领域. 积分中值定理，在积分区间 $[a, b]$ 内存在一点 $\xi$ ，存在

$$
\int_a^b f(x) \mathrm{d} x=(b-a) f(\xi) \tag{1}
$$

该式的几何意义即为: 底为 $b-a$ 而高为 $f(\xi)$ 的矩形的面积恰等于所求曲边梯形的面积 $I$ . 因此，要想求出左端积分，只需要知道三个值: $a, b, f(\xi)$ 即可，这里 $a, b$ 是显然的，问题在于 $\xi$ 的具体位置一般是不清楚的，从而 $f(\xi)$ 末知. 从图像上讲， $f(\xi)$ 称为区间 $[a, b]$ 上的平均高度，目标就是寻求一种求出平均高度 $f(\xi)$ 的算法，这样就能得到我们想要的积分结果.



### 2. 数值积分基本方法

#### 2.1 梯形法

梯形法是数值积分中最简单的方法之一，用区间两端点的 “高度" $f(a)$ 与 $f(b)$ 的算术平均值作为平均高度 $f(\xi)$ 的近 似值，从而导出下述求积公式

$$
\int_a^b f(x) \mathrm{d} x \approx \frac{b-a}{2}[f(a)+f(b)]\tag{2}
$$

相应代码可以表示为

```python
def trapezoidal(f, a, b, n):
    h = (b - a) / n
    # 计算积分的近似值.
    s = 0.5 * (f(a) + f(b))  # 加上区间两端的函数值.
    for i in range(1, n):    # 加上中间所有子区间的函数值.
        x = a + i * h
        s += f(x)
    s *= h
    return s
```

除此之外，如果直接用区间中点坐标 $\frac{a+b}{2}$ 进行替代，那么也可以导出中矩形公式，即为

$$
\int_a^b f(x) \mathrm{d} x \approx (b-a)f(\frac{a+b}{2})\tag{3}
$$

```python
def midpoint(f, a, b, n):
    # 计算每个子区间的宽度.
    h = (b - a) / n

    # 计算积分的近似值.
    s = 0.0
    for i in range(n):
        # 计算每个子区间的中点.
        x = a + (i + 0.5) * h
        # 计算中点处的函数值，并将其加入到积分中.
        s += f(x)
    	# 将所有子区间的贡献相加，并乘以每个子区间的宽度.
    s *= h
    return s
```

**总结:** 更一般性地，可以在区间 $[a, b]$ 上适当选取某些节点 $x_k$ ，然后用 $f\left(x_k\right)$ 的加权平均得 到平均高度 $f(\xi)$ 的近似值，这样构造出来的求积公式具有下列通式

$$
\int_a^b f(x) \mathrm{d} x \approx \sum_{k=0}^n A_k f\left(x_k\right)\tag{4}
$$

其中， $x_k$ 称为求积节点， $A_k$ 称为求积系数，也称作伴随节点 $x_k$ 的权.这种数值积分方法通常称为机械求积，其优势在于将积分求值问题归结为被积函数值的计算，很适合在计算机上使用.



#### 2.2 牛顿-柯特斯(Newton-Cotes)公式

将积分区间 $[a, b]$ 划分为 $n$ 等份，此时步长为 $h=\frac{b-a}{n}$ ，选取等距节点 $x_k=a+k h$ 构造出的插值型求积公式

$$
I_n=(b-a) \sum_{k=0}^n C_k^{(n)} f\left(x_k\right)\tag{5}
$$

称为牛顿-柯特斯(Newton-Cotes)公式，其中 $C_k^{(n)}$ 称为柯特斯系数.可以通过下式确定

$$
C_k^{(n)}=\frac{h}{b-a} \int_0^n \prod_{\substack{j=0 \\ j \neq k}}^n \frac{t-j}{k-j} \mathrm{~d} t=\frac{(-1)^{n-k}}{n k !(n-k) !} \int_0^n \prod_{\substack{j=0 \\ j \neq k}}^n(t-j) \mathrm{d} t\tag{6}
$$

- 当 $n=1$ 时， $C_0^{(1)}=C_1^{(1)}=\frac{1}{2}$, 这时的求积公式便是之前的梯形公式.
- 当 $n=2$ 时，

$$
\begin{gathered}
C_0^{(2)}=\frac{1}{4} \int_0^2(t-1)(t-2) \mathrm{d} t=\frac{1}{6} \\
C_1^{(2)}=-\frac{1}{2} \int_0^2 t(t-2) \mathrm{d} t=\frac{4}{6} \\
C_2^{(2)}=\frac{1}{4} \int_0^2 t(t-1) \mathrm{d} t=\frac{1}{6}
\end{gathered}\tag{7}
$$

对应的就是**辛普森(Simpson)公式：**

$$
I=\frac{b-a}{6}[f(a)+4f(\frac{a+b}{2})+f(b)]\tag{8}
$$

辛普森积分法是梯形积分法的改进型，相比于梯形积分法的顶端以斜线链接，辛普森积分法使用二次函数来模拟，可以得到更精确的结果. 以下有一个简单的证明，方便理解

<img src="https://wowking2018.github.io/img/blog7/fig1.jpg" alt="simpson_int" style="zoom: 100%;" width="500px" />

> 首先，需要求得曲线与坐标轴形成的微元面积.
> 
> $$
> \int_{-d}^d\left(a x^2+b x+c\right) \mathrm{d} x=2 c d+\frac{2}{3} a d^3=\frac{1}{3} d\left(6 c+2 a d^2\right)
> $$
> 
> 接下来需要对这个式子进行改写
> 
> $$
> \begin{aligned}
> & x_1=-d, \quad y_1=a d^2-b d+c \\
> & x_2=0, \quad y_2=c \\
> & x_3=d, \quad y_3=a d^2+b d+c
> \end{aligned}
> $$
> 
> 便有 $y_1+y_3=2 a d^2+2 c, y_1+4 y_2+y_3=6 c+2 a d^2$
> 重写Simpson积分，可以表示为
> 
> $$
> \int_{-d}^d\left(a x^2+b x+c\right) \mathrm{d} x=\frac{1}{3} d\left(y_1+4 y_2+y_3\right)
> $$
> 
> 如果对于一个较大区间 $[a, b]$ ，同时被划分为 $2 n+1$ 个点这样可以表示为
> 
> $$
> \begin{aligned}
> & \int_a^b y \mathrm{d} x \approx \frac{1}{3} d\left(y_1+4 y_2+y_3\right)+\frac{1}{3} d\left(y_3+4 y_4+y_5\right)+\frac{1}{3} d\left(y_{2 n-1}+4 y_{2 n}+y_{2 n+1}\right) \\
> & \approx \frac{1}{3} d\left[y_1+y_{2 n+1}+4\left(y_2+y_4+\ldots+y_{2 n}\right)+2\left(y_3+y_5+\ldots+y_{2 n-1}\right)\right]
> \end{aligned}
> $$



```python
def simpson(f, a, b, n):
    # 计算每个子区间的宽度.
    h = (b - a) / n

    # 计算积分的近似值.
    s = f(a) + f(b)
    for i in range(1, n):
        x = a + i * h
        if i % 2 == 0:
            s += 2 * f(x)
        else:
            s += 4 * f(x)

    # 将所有子区间的贡献相加，并乘以每个子区间的宽度.
    s *= h / 3

    return s
```

当 $n=4$ 时，可以特别称为科特斯公式，具体形式为[^1]

$$
C=\frac{b-a}{90}\left[7 f\left(x_0\right)+32 f\left(x_1\right)+12 f\left(x_2\right)+32 f\left(x_3\right)+7 f\left(x_4\right)\right]\tag{9}
$$

```python
def cotes(f, a, b, n):
    # Cotes Formula
    # (b-a)/90 * (7*f(x0) + 32*f(x1) + 12*f(x2) + 32*f(x3) + 7*f(x4))
    h = (b - a) / n
    x = [a + i * h for i in range(n+1)]
    I = sum((x[i+1] - x[i]) / 90 * (7*f(x[i]) + 32*f((x[i+1] + 3*x[i]) / 4) + 12*f((2*x[i+1] + 2*x[i]) / 4) + 32*f((3*x[i+1] + x[i]) / 4) + 7*f(x[i+1])) for i in range(n))
    return I
```

以上代码由[^2]中matlab代码改编而来。



#### 2.3 龙格(Romberg)求积公式

复合求积方法可提高求积精度，如若精度仍不够，则可通过将步长逐次减半的方式来提高精度. 如对复合梯形公式可导出其递推公式

$$
T_{2 n}=\frac{1}{2} T_n+\frac{h}{2} \sum_{k=0}^{n-1} f\left(x_{k+\frac{1}{2}}\right)\tag{10}
$$

其中 $T_{2 n}$ 表示在 $T_n$ 基础上步长 $h$ 减半后的积分值.

> **定理：**
>
> 设 $f(x) \in C^{\infty}[a, b]$ ，则有
> 
> $$
> T(h)=I+\alpha_1 h^2+\alpha_2 h^4+\cdots+\alpha_l h^{2 l}+\cdots
> $$
> 
> 其中， $T(h)=T_n$ ，系数 $\alpha_l(l=1,2, \cdots)$ 与 $h$ 无关. $T(h) \approx I$ 是 $O\left(h^2\right)$ 阶，若用 $\frac{h}{2}$ 代替 $h$ ，有
> 
> $$
> T\left(\frac{h}{2}\right)=I+\alpha_1 \frac{h^2}{4}+\alpha_2 \frac{h^4}{16}+\cdots+\alpha_l\left(\frac{h}{2}\right)^{2 l}+\cdots
> $$
> 
> 两项结合可以得到
>
> $$
> S(h)=\frac{4 T\left(\frac{h}{2}\right)-T(h)}{3}=I+\beta_1 h^4+\beta_2 h^6+\cdots ;
> $$
> 
> 这里 $\beta_1, \beta_2, \cdots$ 是与 $h$ 无关的系数.用近似积分值 $I$ ，其误差阶为 $O\left(h^4\right)$ ，显然误差阶是提高了.类似这种将计算 $I$ 的近似值的误差阶由 $O\left(h^2\right)$ 提高到 $O\left(h^4\right)$ 的方法称为外推算法，也称为理查德森 (Richardson)外推算法.这是 "数值分析" 中一个重要的技巧，只要真值与近似值的误差能够表示成 $h$ 的幂级数，都可以使用外推算法来提高精度.

按照文献[3]中的说法， 引入相应的记号并改写公式可以得到

$$
\begin{equation}
    T_m(h)=\frac{4^m}{4^m-1} T_{m-1}\left(\frac{h}{2}\right)-\frac{1}{4^m-1} T_{m-1}(h),
\end{equation} \tag{11}
$$

经过 $m$ 次理查德森外推加速方法后

$$
\begin{equation}
    T_m(h)=I+\delta_1 h^{2(m+1)}+\delta_2 h^{2(m+2)}+\cdots
\end{equation}\tag{12}
$$

设用 $T_0^{(k)}$ 表示二分 $k$ 次后求得的梯形值，且以 $T_m^{(k)}$ 表示序列 $T_0^{(k)}$ 的 $m$ 次加速值，则由递推公式 (11) 可得

$$
T_m^{(k)}=\frac{4^m}{4^m-1} T_{m-1}^{(k+1)}-\frac{1}{4^m-1} T_{m-1}^{(k)}, \quad k=1,2, \cdots \tag{13}
$$

上次则称为龙贝格求积算法，计算过程如下:

**Step1.** 取 $k=0, h=b-a$, 求 $T_0^{(0)}=\frac{h}{2} [f(a)+f(b)]$ 。令 $1 \rightarrow k$ （ $k$ 记区间 $[a, b]$ 的二分次数）。

**Step2.** 求梯形值 $T_0\left (\frac {b-a}{2^k}\right )$, 即按递推公式 (11) 计算 $T_0^{(k)}$ 。

**Step3.** 求加速值。

**Step4.** 若 $\left\vert {T_k^{(0)}-T_{k-1}}\right \vert <\epsilon$ （预先给定的精度）,则终止计算,并且 $T_k^{(0)} \approx I$ ;否则令 $k+1 \rightarrow k$ 转 **Step2** 继续计算。

```python
def Romberg(f, a, b, eps=1e-8):
    h = b - a
    T = [[h * (f(a) + f(b)) / 2]]
    n = 1
    k = 0
    err = 1
    
    while err > eps:
        k += 1
        S = 0
        
        for ii in range(1, n + 1):
            x = a + h * (2 * ii - 1) / 2
            S += f(x)
            
        T.append([(T[k - 1][0] + h * S) / 2])
        
        for m in range(1, k + 1):
            T[k].append((4 ** m * T[k][m - 1] - T[k - 1][m - 1]) / (4 ** m - 1))
            
        err = abs(T[k][k] - T[k][k - 1])
        n *= 2
        h /= 2
        
    return T[k][k]

```


#### 2.4 自适应积分法

复合求积方法通常适用于被积函数变化不太大的积分，如果在求积区间中被积函数变化很大，有的部分函数值变化剧烈，另一部分却变化平缓.[^3] 这时如果统一将区间等分再用复合求积公式计算积分将会导致计算量很大，如果想实现的是在满足误差要求的前提下，对变化剧烈部分将区间细分，而平缓部分则可使用大步长，也即针对被积函数在区间上不同情形采用不同的步长，使得再满足精度前提下积分计算工作量尽可能小.其算法技巧是在不同区间上预测被积函数变化的剧烈程度确定相应步长，这就是**自适应积分方法**的基本思想.

``` python
def self_adaptive_simpson(a, b, epsilon, S):
    def f(x):
        return 1 / (x ** 2)

    h = (b - a) / 2
    S1 = h / 6 * (f(a) + 4 * f(a + h / 2) + f(a + h))
    S2 = h / 6 * (f(a + h) + 4 * f(a + 3 * h / 2) + f(b))

    if abs(S - S1 - S2) <= epsilon:
        I = (S1 + S2) + (S1 + S2 - S) / 15
    else:
        I = (
            self_adaptive_simpson(a, (a + b) / 2, epsilon / 2, S1)
            + self_adaptive_simpson((a + b) / 2, b, epsilon / 2, S2)
        )

    return I
```


### Reference
[^1]: [Newton–Cotes formulas - Wikipedia](https://en.wikipedia.org/wiki/Newton–Cotes_formulas)

[^2]: [数值积分常用方法](https://zhuanlan.zhihu.com/p/166272592)

[^3]: 李庆扬, 王能超, 易大义. 数值分析[M]. 华中科技大学出版社, 2006.
